#### ***Вступ***
Останні генеративні моделі показали блискучі результати в області створення реалістичних зображень на певну тематику. З подальшим розвитком генеративно-змагальних мереж на основі стилів, виникає питання, чи можливо здійснювати редагування реального зображення, використовуючи результати генеративних моделей. Автоматичне редагування зображення дозволило б пришвидшити процес збору необхідних даних для подальших досліджень, наприклад, тренування нейронної мережі з використанням зображень певного класу. Для того, щоб мінімізувати втручання суб’єкта в процес редагування, напрямок у редагуванні зображення пропонується визначати за текстовим запитом. Даний сервіс також може стати чудовим інструментом для розваг людей різних соціальних груп. 

#### ***Мета***
Спрощення процесу редагування зображень за рахунок  використання текстового інтерфейсу користувача.

#### ***Деталі реалізації***
Оскільки редагування зображення з використанням нейронних мереж вимагає велику кількість даних певної категорії, сервіс буде присвячений саме редагуванню зовнішності людей за допомогою текстової інструкції.

***PS***:  При наявності навчальних даних іншої категорії, розроблені методи чудово справляються з редагуванням інших обʼєктів.

#### ***Завдання сервісу***
- Реалізувати метод оптимізації латентного простору;
- Реалізувати метод прихованого маперу, який навчається окремо для текстового запиту. Це означає, що на виході отримані ваги моделі дозволять редагувати будь-яке зображення для попередньо натренованого текстового запиту.

#### ***Методи та моделі для вирішення поставленого завдання***
Багато робіт досліджують можливість використання латентного простору натренованого генератора для редагування зображення. Зокрема, використання проміжного латентного простору StyleGAN дозволить виконувати суттєві маніпуляції над зображенням. Оскільки редагування зображення відбуватиметься за текстовим описом, пропонується використовувати попередньо навчену модель CLIP як інструмент контролю.

#### ***StyleGAN***
StyleGAN – це генеративно-змагальна мережа, яка має змогу контролювати стиль, певні атрибути згенерованого зображення. Дана модель була представлена компанією NVDIA у статті “A Style-Based Generator Architecture for Generative Adversarial Networks”. Поєднання класичної генеративно-змагальної мережі (GAN) та розмежованого прихованого простору дозволило генерувати реалістичні зображення з високою роздільною здатністю.

#### ***CLIP***
CLIP – це перша мультимодальна модель, яка містить в собі поєднання пар зображення-текст і використовується у сфері комп’ютерного зору. Дана модель була запропонована компанією OpenAI та випущена 5 січня 2021 року. CLIP – це своєрідний міст між комп’ютерним зором та природною обробкою мови.
Дана модель натренована на 400 мільйонах пар зображення – текст. У результаті тренування CLIP може згенерувати релевантний фрагмент тексту або повернути короткий опис для заданого зображення. Також варто зауважити, що CLIP володіє такою особливістю як «навчання з нуля». «Навчання з нуля» - це здатність моделі передбачити клас, який вона не бачила у навчальних даних. Така модель як CLIP, через те, що вона використовує текстову інформацію в парах зображення – текст, як правило, дуже добре справляється з навчанням з нуля. Це означає, що навіть якщо зображення, яке ви подаєте на вхід суттєво відрізняється від навчальних даних, то модель швидше за все зможе правильно передбачити підпис до цього зображення. 

#### ***Метод оптимізації латентного простору***
Розглянемо метод латентної оптимізації, де заданий латентний код зображення у просторі StyleGAN змінюється шляхом мінімізації функції витрат, обчисленої у просторі CLIP.
Основна ідея даного методу полягає в тому, щоб змінювати латентний код зображення на основі мінімізації відстані від вектору заданого зображення до вектору тексту. Оскільки модель CLIP передбачає, що подібні пари зображення-текст мають колінеарні вектори, це дозволяє використовувати дану закономірність для редагування латентного вектору зображення. Нейронна мережа з кожною ітерацією буде змінювати прихований вектор зображення, який керується функцією витрат з використанням моделі CLIP. StyleGAN в свою чергу використовується виключно для якісної генерації зображення на основі прихованого коду.

#### ***Метод прихованого мапера***
Оскільки оптимізація латентного простору для окремого зображення займає доволі багато часу, було запропоновано використовувати метод прихованого мапера. Даний метод полягає у використанні нейронної мережі, яка натренована для окремої текстової інструкції t та з кожною ітерацією виконує маніпулятивний крок M_t (w) для будь-якого зображення з латентним кодом w.
Різні шари моделі StyleGAN відповідають за різні рівні деталізації згенерованого зображення. Отож, при реалізації мапера було прийнято рішення розділити шари на три різні групи. Кожен шар отримуватиме на вхід частину прихованого вектору зображення. Відповідно три окремі нейронні мережі отримуватимуть на вхід по одній групі прихованого шару та частину вектору зображення. Архітектура цих нейронних мереж подібна до архітектури StyleGAN, але з меншою кількістю шарів.
У цілому прихований мапер навчений маніпулювати атрибутами зображення, спираючись на текстовий опис та зберігаючи при цьому усі необхідні деталі оригінального зображення задля збереження правдоподібності. 
Прихований вектор зображення w ділиться на три частини, кожна з яких подається на вхід окремої нейронної мережі (мапера). На виході ми отримуємо вектор залишків, ваги якого додаються до початкового вектору w та подаються на вхід у StyleGAN. Далі виконується підрахунок функції витрат та L2 норми, значення яких використовується у фінальній функції витрат, яку ми намагаємось мінімізувати. На кожній ітерації значення вагів вектору w змінюються, поки не буде досягнуто бажаного результату. Кількість ітерацій може буде визначена константою або регулюватись програмно через значення функції витрат, яку ми обчислюємо.
